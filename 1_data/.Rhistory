setwd("C:/Users/User/Desktop/MA/1_data")
# code for data analysis of study on fragments
# set up
library("tidyverse")
library("tidyr")
library("ggplot2")
library("Rmisc")
library("lme4")
library("lmerTest")
library("emmeans")
library("dplyr")
library("aida")
library("pwr")
# read in data
all.dat <- read.csv("dat_pilot_study.csv", sep=";", header=TRUE)
# information about participants
# age
min(all.dat$age, na.rm=T)
# 22 in pilot study
max(all.dat$age, na.rm=T)
# 54 in pilot study
mean(all.dat$age, na.rm=T)
# 26.9 in pilot study
# gender
table(all.dat$gender)/56 #divided by 56 because every participants had 56 trials
# mÃ¤nnlich  weiblich
# 2         9
# in pilot study
# education
table(all.dat$education) /56 #divided by 56 because every participants had 56 trials
#H\xf6herer Abschluss     Abitur             Bachelor
#1                        3                    6
#kein Abitur
#1
# in pilot study
# number of participants in each between-subject condition, i.e., written and auditory
table(all.dat$modality)  /56
# auditory  written
# 2         9
# in pilot study
nrow(all.dat)
# 616 in pilot study
# participants' comments on study
all.dat %>% pull(comments) %>% unique()
# data sorting and cleaning
# put all filler items in a seperate data set
fillerDat <- all.dat[all.dat$trial_type == "Filler",]
# rename column in filler dataset to varying acceptabiltiy of filler stimuli (A-E)
colnames(fillerDat)[colnames(fillerDat) == "fragmentType_Acceptability"] = "acceptability"
# only use critical items for analysis
dat <- all.dat[all.dat$trial_type == "Critical",]
# rename column with fragment type
colnames(dat)[colnames(dat) == "fragmentType_Acceptability"] = "fragment_type"
nrow(dat) == nrow(fillerDat)
# TRUE
# -------------------- Data plotting --------------------
# plotting filler items with varying acceptability
fillerDat %>%
ggplot(aes(x= acceptability, y = as.numeric(response))) +
geom_boxplot (width =0.3) +
labs(title = "Perceived naturalness of filler items wth varying acceptability",
x = "varying acceptability", y = "perceived naturalness") +
scale_x_discrete(name = "acceptability",
labels = c("A (full acceptablity)", "B (partial acceptability)",
"C (neutrality in terms of acceptability)",
"D (partial unacceptability)", "E (full unacceptability)"))+
scale_y_continuous(breaks=c(1:8))
# emphasis
dat %>%
ggplot(aes(x = emphasis, y = as.numeric(response), color = emphasis)) +
geom_jitter(height = 0) +
labs(title = "Perceived naturalness of stimuli with and wihtout emphasis",
x = "emphasis", y = "perceived naturalness") +
scale_y_continuous(breaks=c(1:8))
# modality
dat %>%
ggplot(aes(x = modality, y = as.numeric(response), color = modality)) +
geom_jitter(height = 0) +
labs(title = "Perceived naturalness of auditory and written stimuli",
x = "modality", y = "perceived naturalness") +
scale_y_continuous(breaks=c(1:8))
# fragment type
dat %>%
ggplot(aes(x = fragment_type, y = as.numeric(response),
color = fragment_type)) +
geom_jitter(height = 0) +
labs(title = "Perceived naturalness of functional and lexical fragments",
x = "fragment type", y = "perceived naturalness") +
scale_x_discrete(labels=c("functional", "lexical")) +
scale_color_discrete(name = "fragment type",
labels = c("functional", "lexical"))+
scale_y_continuous(breaks=c(1:8))
# modality and emphasis in one graph
dat %>%
ggplot(aes(x = emphasis, y = as.numeric(response), color = emphasis)) +
geom_jitter(height = 0) +
labs(title = "Auditory and written stimuli with and without emphasis",
x = "emphasis", y = "perceived naturalness") +
facet_wrap(~modality) +
scale_y_continuous(breaks=c(1:8))
# emphasis and fragment type in one graph
dat %>%
ggplot(aes(x = fragment_type, y = as.numeric(response),
color = fragment_type)) +
geom_jitter(height = 0) +
labs(title = "Functional and lexical fragments with and without emphasis",
x = "fragment type", y = "perceived naturalness", color = "fragment type") +
scale_x_discrete(labels=c("functional", "lexical")) +
scale_color_discrete(name = "fragment type",
labels = c("functional", "lexical")) +
facet_grid(~emphasis) +
scale_y_continuous(breaks=c(1:8))
# modality and fragment type in one graph
dat %>%
ggplot(aes(x = fragment_type, y = as.numeric(response),
color = fragment_type)) +
geom_jitter(height = 0) +
labs(title = "Auditory and written stimuli with functional and lexical fragments",
x = "fragment type", y = "perceived naturalness", color = "fragment type") +
scale_x_discrete(labels=c("functional", "lexical")) +
scale_color_discrete(name = "fragment type",
labels = c("functional", "lexical")) +
facet_grid(~modality) +
scale_y_continuous(breaks=c(1:8))
# all factors in one graph
dat %>%
ggplot(aes(x = fragment_type, y = as.numeric(response),
color = fragment_type)) +
geom_jitter(height = 0) +
labs(title = "Participants' ratings of all critical items",
x = "fragment type", y = "perceived naturalness",
color = "fragment type") +
scale_x_discrete(labels=c("functional", "lexical")) +
scale_color_discrete(name = "fragment type",
labels = c("functional", "lexical")) +
facet_grid(emphasis~modality) +
scale_y_continuous(breaks=c(1:8))
# including means and standard deviation
# emphasis
sumStatsEmp <- summarySE(dat, measurevar ="response", groupvars = "emphasis")
sumStatsEmp %>%
ggplot(aes(x = emphasis, y = as.numeric(response), color = emphasis)) +
geom_point() +
labs(y="percevied naturalness")+
geom_errorbar(aes(ymin = as.numeric(response)-ci,
ymax = as.numeric
# modality
sumStatsMod <- summarySE(dat, measurevar ="response", groupvars = "modality")
# modality
sumStatsMod <- summarySE(dat, measurevar ="response", groupvars = "modality")
# fragment type
sumStatsFrag <- summarySE(dat, measurevar ="response", groupvars = "fragment_type")
# all factors included
sumStats <- summarySE(dat, measurevar ="response",
groupvars = c("emphasis", "modality", "fragment_type"))
sumStats$ci <- sumStatsMod$ci
#choosing one of the ci columns to ensure consistency when specifying ymin and ymax
sumStats %>%
ggplot(aes(x= emphasis, y = as.numeric(response))) +
geom_point() +
geom_errorbar(aes(ymin = as.numeric(response) - ci,
ymax = as.numeric(response) + ci), width = 0.1) +
ylim(1, 8) +
facet_grid(fragment_type ~ modality)
# z-score the responses
responses_z <- scale(as.numeric(dat$response))
dat$responses_z <- responses_z
# First hypothesis
# H0: There is no significant difference between stimuli with and without emphasis.
# H1: Stimuli with emphasis receive higher acceptability ratings than stimuli without emphasis.
# tested by linear mixed model
# as by this method:
modelemp <- lmer(data = dat, responses_z ~ emphasis + (1|submission_id))
summary(modelemp)
# Second hypothesis
# H0: There is no significant difference between auditory and written stimuli.
# H1: Auditory stimuli receive higher acceptability ratings than written stimuli.
# tested by linear mixed model
# as by this method:
modelmod <- lmer(data=dat, responses_z ~ modality + (1|submission_id))
# Second hypothesis
# H0: There is no significant difference between auditory and written stimuli.
# H1: Auditory stimuli receive higher acceptability ratings than written stimuli.
# tested by linear mixed model
# as by this method:
modelmod <- lmer(data=dat, responses_z ~ modality + (1|submission_id))
# Second hypothesis
# H0: There is no significant difference between auditory and written stimuli.
# H1: Auditory stimuli receive higher acceptability ratings than written stimuli.
# tested by linear mixed model
# as by this method:
modelmod <- lmer(data=dat, responses_z ~ modality + (1|submission_id))
summary(modelmod)
# p value = 0.721 in pilot study
# We judge there to be evidence in favor of the second hypothesis, if the p-value is less than 0,05.
# Third hypothesis
# H0: There is no significant difference between stimuli with lexical and functional fragments.
# H1: Stimuli with lexical fragments receive higher acceptability ratings than stimuli with functional fragments
# tested by linear mixed model
# as by this method:
modelfrag <- lmer(data=dat, responses_z ~ fragment_type + (1|submission_id))
summary(modelfrag)
# p value = 0.313 in pilot study
# We judge there to be evidence in favor of the third hypothesis, if the p-value is less than 0,05.
#--- power analysis based on pilot study ---
#--- power analysis based on pilot study ---
# Function to calculate Cohen's f for a pair of means and standard deviations
cohen_f <- function(mean1, mean2, sd1, sd2) {
if (is.na(sd1) || is.na(sd2) || sd1 == 0 || sd2 == 0) {
return(NA)  # Return NA for undefined effect sizes
}
pooled_sd <- sqrt(((sd1^2 + sd2^2) / 2))
(mean1 - mean2) / pooled_sd
}
# Calculate means and standard deviations for each combination of conditions
means_sd <- dat %>%
group_by(emphasis, modality, fragment_type) %>%
summarize(
mean_response = mean(response),
sd_response = sd(response)
) %>%
filter(!is.na(sd_response) & sd_response != 0)
# Check if there are valid rows to calculate Cohen's f
if (nrow(means_sd) > 1) {
# Get unique values of emphasis for combination
unique_emphasis <- unique(means_sd$emphasis)
# Calculate Cohen's f for all combinations of conditions
cohens_f <- t(combn(unique_emphasis, 2, function(comb) {
condition1 <- comb[1]
condition2 <- comb[2]
mean1 <- means_sd$mean_response[means_sd$emphasis == condition1]
mean2 <- means_sd$mean_response[means_sd$emphasis == condition2]
sd1 <- means_sd$sd_response[means_sd$emphasis == condition1]
sd2 <- means_sd$sd_response[means_sd$emphasis == condition2]
cohen_f(mean1, mean2, sd1, sd2)
}))
# Filter out any NA values from cohens_f and flatten the matrix
cohens_f <- c(cohens_f[!is.na(cohens_f)])
# Check if there are any valid effect sizes to proceed with power analysis
if (length(cohens_f) > 0) {
# Calculate the maximum effect size from cohens_f
max_effect_size <- max(cohens_f, na.rm = TRUE)
# Parameters for power analysis
alpha <- 0.05
power <- 0.80
f <- max_effect_size
groups_per_factor <- 2
# Conduct power analysis
sample_size <- pwr.anova.test(k = groups_per_factor, f = f, sig.level = alpha, power = power)
required_sample_size <- sample_size$n
cat("Maximum Effect Size (Cohen's f):", f, "\n")
cat("Required Sample Size per Group:", required_sample_size, "\n")
} else {
cat("Error: Unable to calculate Cohen's f for the pilot data.\n")
cat("Please ensure that the pilot data contains valid values for effect size calculation.\n")
}
} else {
cat("Error: Insufficient data for calculating Cohen's f.\n")
cat("Please ensure that the pilot data contains enough valid data points for each combination of conditions.\n")
}
#-------------------- Power analysis --------------------
# Set effect size, alpha, and power values (adjust as needed)
effect_size <- 0.3  # Small effect size
alpha <- 0.05       # Significance level (5%)
power <- 0.80       # Desired power (80%)
# Conduct power analysis
sample_size <- pwr.t.test(d = effect_size, sig.level = alpha, power = power)
# Display the required sample size
cat("Required Sample Size per Group:", ceiling(sample_size$n), "\n")
